# train.py Config - Training
train:
  useInteractionDataset: True
  dataset: '../../../dataset'

  datasetsMatterportTrain:
  datasetsMatterportVal:
  datasetsScannetTrain:
  datasetsScannetVal:

  # Training/Validation Params
  model: 'drn' # Possible values: ['drn', 'deeplab_xception', 'deeplab_resnet']
  batchSize: 64
  batchSizeMatterport: 0
  batchSizeScannet: 0
  validationBatchSize: 64
  testBatchSize: 64
  numEpochs: 100
  imgHeight: 256
  imgWidth: 256
  numClasses: 3
  numInputChannels: 3 # Num of channels in input image. RGB = 3 channels, Grayscale = 1 channel.
  numWorkers: 1 # Num of workers used in the dataloader
  logsDir: '../../training/surface_normals' # Directory where logs of each exp will be saved.
  lossFunc: 'cosine' # Possible values: ['cosine', 'radians']
  percentageDataForTraining: 1.0 # The percentage of images in dataset to be used for training. Rest used for validation.
  percentageDataForMatterportTraining: 0.0109 # 0.218  # The percentage of images in dataset to be used for training.
  percentageDataForScannetTraining: 0.052
  percentageDataForMatterportVal: 0.047
  percentageDataForScannettVal:  0.0601
  percentageDataForValidation: 1.0

  # Deeplab specific
  outputStride: 8 # Possible values: [8, 16]. Output stride for deeplabv3 model. Smaller values give finer details in output mask.
  epochSize: 1 # After these many epochs, change learning rate

  continueTraining: False  # If true, continue training from a checkpoint
  pathPrevCheckpoint: '../../training/surface_normals/exp-005/checkpoints/checkpoint-epoch-0002.pth' # Path to .pth checkpoint file to load to continue training from
  initOptimizerFromCheckpoint: False  # Re-Initialize optimizer's state from checkpoint. NOTE: when this is enabled, value of learningRate will be overridden with value from checkpoint.
  loadEpochNumberFromCheckpoint: False # If true, the epoch/iter numbering will start from the checkpoint's last epoch num.

  saveImageInterval: 1 # every N epochs, log output images to tensorboard
  saveImageIntervalIter: 100 # Every N iterations, log output images to tensorboard
  testInterval: 1 # Run on test set every nTestInterval epochs. Keep at 0 to skip tests.
  saveModelInterval: 2 # Save the model checkpoints every N epochs

  # Optimizer Params
  optimAdam:
    learningRate: 0.0001
    weightDecay: 0 # Other values: 0.0001
  optimSgd:
    learningRate: 1e-6
    momentum: 0.9
    weight_decay: 5e-4
  lrScheduler: 'lr_poly' # Possible Values: ['', 'StepLR', 'ReduceLROnPlateau']
  lrSchedulerStep:
    step_size: 4
    gamma: 0.9
  lrSchedulerPlateau:
    factor: 0.8
    patience: 25
    verbose: True

# eval.py Config - Validation/Testing Inference
eval:
  # Synthetic datasets with ground truth labels
  # Used as validation set
  datasetsSynthetic:
    - images: ''
      labels: ''

  # Datasets of real images, no labels available
  # Used as Test set
  datasetsReal:
    - images: ''

  # Params
  model: 'drn' # Possible values: ['drn', 'deeplab_xception', 'deeplab_resnet']
  numClasses: 3
  batchSize: 16
  imgHeight: 256
  imgWidth: 256
  numWorkers: 4 # Num of workers used in the dataloader
  pathWeightsFile: 'data/models/normals/checkpoint-normals.pth' # Path to the checkpoint to be loaded
  resultsDirSynthetic: 'data/results/test-synthetic' # The dir to which results on synthetic images will be stored
  resultsDirReal: 'data/results/test-real'  # The dir to which results on real images will be stored
  resultsWeightsSubDir: 'occlusion-weights' # The prediction of model will be converted to occlusion weights (for depth2depth) in this subfolder within each results folder
  resultsWeightsVizSubDir: 'occlusion-weights-viz' # The visualization of the occlusion weights will be saved in this subfolder within resultsWeightsSubDir
